import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
os.environ['OMP_NUM_THREADS'] = '1'

import json
import faiss
import torch
from openai import OpenAI
from dotenv import load_dotenv
from prompt import *
from sentence_transformers import SentenceTransformer

load_dotenv('.env', override=True)
API_KEY = os.getenv("OPENAI_API_KEY")

PERSONA_MAP = {
    1: "pme",
    2: "nowon",
    3: "ob",
    4: "moyeon",
    5: "seoksa",
    6: "promie"
}


NEGATIVE_MAP = {
    "fit": {
        1: "ì˜¤ë²„ì‚¬ì´ì¦ˆ",
        2: "ìŠ¬ë¦¼",
        3: ""
    },
    "pattern": {
        1: "ë¡œê³ ",
        2: "ìŠ¤íŠ¸ë¼ì´í”„",
        3: "ì²´í¬",
        4: ""
    },
    "price": {
        1: 100000,
        2: 200000,
        3: 300000,
        4: 500000,
        5: 500000
    }
}

GENDER_MAP = {
    "pme": "ë‚¨ì",
    "nowon": "ë‚¨ì",
    "ob": "ë‚¨ì",
    "moyeon": "ì—¬ì",
    "seoksa": "ì—¬ì",
    "promie": "ì—¬ì"
}

PERSONA_MOOD = {
    "pme": ["ìºì£¼ì–¼", "ë‹¨ì •", "í”„ë ˆí”¼","ë‚¨ì¹œë£©"],
    "moyeon": ["ìŠ¤íŠ¸ë¦¿"],
    "seoksa": ["ìºì£¼ì–¼", "í¸í•¨"],
    "promie": ["ì—¬ì„±ìŠ¤ëŸ¬ì›€", "ì‹œí¬", "ë‹¨ì •"],
    "nowon": ["ë¯¸ë‹ˆë©€", "ìºì£¼ì–¼"],
    "ob": ["ìŠ¤íŠ¸ë¦¿", "ì›Œí¬ì›¨ì–´"],
}

DETAIL_MAP = {
    "sub_cat_name": {
        "ìƒì˜": ['ê¸´ì†Œë§¤ í‹°ì…”ì¸ ', 'ë‹ˆíŠ¸/ìŠ¤ì›¨í„°', 'í›„ë“œ í‹°ì…”ì¸ ', 'ì…”ì¸ /ë¸”ë¼ìš°ìŠ¤', 'í”¼ì¼€/ì¹´ë¼ í‹°ì…”ì¸ ', 'ë§¨íˆ¬ë§¨/ìŠ¤ì›¨íŠ¸'],
        "ë°”ì§€": ['ë°ë‹˜ íŒ¬ì¸ ', 'ì½”íŠ¼ íŒ¬ì¸ ', 'ìŠˆíŠ¸ íŒ¬ì¸ /ìŠ¬ë™ìŠ¤', 'íŠ¸ë ˆì´ë‹/ì¡°ê±° íŒ¬ì¸ '],
        "ì•„ìš°í„°": ['ë¡±íŒ¨ë”©/í—¤ë¹„ ì•„ìš°í„°', 'ë¬´ìŠ¤íƒ•/í¼', 'í”Œë¦¬ìŠ¤/ë½€ê¸€ì´', 'ê²¨ìš¸ ì‹±ê¸€ ì½”íŠ¸', 'ìˆíŒ¨ë”©/í—¤ë¹„ ì•„ìš°í„°', 'ìŠˆíŠ¸/ë¸”ë ˆì´ì € ì¬í‚·', 'ì¹´ë””ê±´', 'í›„ë“œ ì§‘ì—…'],
        "ì‹ ë°œ": ['ìŠ¤ë‹ˆì»¤ì¦ˆ', 'ë¶€ì¸ /ì›Œì»¤', 'êµ¬ë‘', 'íŒ¨ë”©/í¼ ì‹ ë°œ'],
        "ê°€ë°©": ['ë°±íŒ©', 'ë©”ì‹ ì €/í¬ë¡œìŠ¤ ë°±', 'ì—ì½”ë°±', 'ìˆ„ë”ë°±']
    },
    "color": {
        "ìƒì˜": ['ë¸”ë™', 'í™”ì´íŠ¸', 'ì°¨ì½œ', 'ê·¸ë¦°', 'ê·¸ë ˆì´', 'ë„¤ì´ë¹„', 'ë¸Œë¼ìš´', 'í•‘í¬', 'ë¸”ë£¨', 'ë²„ê±´ë””'],
        "ë°”ì§€": ['ë¸”ë™', 'í™”ì´íŠ¸', 'ì°¨ì½œ', 'ê·¸ë ˆì´', 'ë„¤ì´ë¹„', 'ë¸Œë¼ìš´', 'ë¸”ë£¨'],
        "ì•„ìš°í„°": ['ë¸”ë™', 'í™”ì´íŠ¸', 'ì°¨ì½œ', 'ê·¸ë¦°', 'ê·¸ë ˆì´', 'ë„¤ì´ë¹„', 'ë¸Œë¼ìš´', 'í•‘í¬', 'ë¸”ë£¨', 'ë²„ê±´ë””'],
        "ì‹ ë°œ": ['ë¸”ë™', 'í™”ì´íŠ¸', 'ì°¨ì½œ', 'ê·¸ë ˆì´', 'ë„¤ì´ë¹„', 'ë¸Œë¼ìš´', 'ë¸”ë£¨'],
        "ê°€ë°©": ['ë¸”ë™', 'í™”ì´íŠ¸', 'ì°¨ì½œ', 'ê·¸ë¦°', 'ê·¸ë ˆì´', 'ë„¤ì´ë¹„', 'ë¸Œë¼ìš´', 'ë¸”ë£¨', 'ë²„ê±´ë””']
    },
    "fit": {
        "ìƒì˜": ['ìŠ¬ë¦¼', 'ë ˆê·¤ëŸ¬', 'ì˜¤ë²„ì‚¬ì´ì¦ˆ'],
        "ë°”ì§€": ['ë ˆê·¤ëŸ¬', 'ì˜¤ë²„ì‚¬ì´ì¦ˆ'],
        "ì•„ìš°í„°": ['ë ˆê·¤ëŸ¬']
    },
    "pattern": {
        "ìƒì˜": ['ë‹¨ìƒ‰', 'ë¡œê³ /ê·¸ë˜í”½', 'ìŠ¤íŠ¸ë¼ì´í”„', 'ì²´í¬'],
        "ë°”ì§€": ['ë‹¨ìƒ‰', 'ë¡œê³ /ê·¸ë˜í”½'],
        "ì•„ìš°í„°": ['ë‹¨ìƒ‰', 'ë¡œê³ /ê·¸ë˜í”½'],
        "ê°€ë°©": ['ë¡œê³ /ê·¸ë˜í”½', 'ê¸°íƒ€íŒ¨í„´', 'ë‹¨ìƒ‰']
    },
    "texture": {
        "ìƒì˜": ['ë©´', 'ë‹ˆíŠ¸', 'í´ë¦¬ì—ìŠ¤í…Œë¥´'],
        "ë°”ì§€": ['í´ë¦¬ì—ìŠ¤í…Œë¥´', 'ë©´', 'ë‚˜ì¼ë¡ '],
        "ì•„ìš°í„°": ['ë‚˜ì¼ë¡ ', 'ìš¸', 'ë‹ˆíŠ¸', 'ë©´', 'í´ë¦¬ì—ìŠ¤í…Œë¥´'],
        "ì‹ ë°œ": ['ì²œì—°ê°€ì£½', 'ìŠ¤ì›¨ì´ë“œ', 'í´ë¦¬ì—ìŠ¤í…Œë¥´', 'ì¸ì¡°ê°€ì£½'],
        "ê°€ë°©": ['ë‚˜ì¼ë¡ ', 'ë©´', 'í´ë¦¬ì—ìŠ¤í…Œë¥´']
    }
    
}

# ===============================
# 0. Utils
# ===============================

from openai import OpenAI
import os, json, faiss, torch
import numpy as np
from sentence_transformers import SentenceTransformer

def tpo_to_text(tpo_val):
    """tpoê°€ list/str/None ì„ì—¬ ë“¤ì–´ì™€ë„ ê²€ìƒ‰ì¿¼ë¦¬ì— ì•ˆì „í•˜ê²Œ ë„£ê¸°"""
    if tpo_val is None:
        return ""
    if isinstance(tpo_val, list):
        return ", ".join([str(x) for x in tpo_val if x])
    return str(tpo_val)

def safe_join(parts):
    # "", None ì œê±° + ì¤‘ë³µ ì œê±°
    cleaned = []
    for p in parts:
        if not p:
            continue
        p = str(p).strip()
        if not p:
            continue
        cleaned.append(p)
    return ", ".join(list(dict.fromkeys(cleaned)))

# ===============================
# 1. Load Model & DB
# ===============================

def load_embedding_model():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"â¡ï¸ DEVICE: {device}")
    print("ğŸ‘‰ Embedding model is loading...")
    model = SentenceTransformer("upskyy/bge-m3-korean", device=device)
    model.eval()
    return model

def embed_text(text: str, model):
    with torch.no_grad():
        vec = model.encode(
            text,
            convert_to_numpy=True,
            normalize_embeddings=True
        )
    return vec.astype("float32")


def load_db(db_dir):
    index_path = os.path.join(db_dir, "index.faiss")
    # index = faiss.read_index(index_path)
    index = faiss.read_index(index_path, faiss.IO_FLAG_MMAP | faiss.IO_FLAG_READ_ONLY)
    metas = [json.loads(l) for l in open(os.path.join(db_dir, "metadata.jsonl"), encoding="utf-8")]
    return index, metas


def load_all_dbs(style_root, tpo_root, categories):
    db_cache = {"style": {}, "tpo": {}}
    print("ğŸ‘‰ DB cache is loading...")
    for cat in categories:
        # tpo DBëŠ” í•­ìƒ ì¡´ì¬
        db_cache["tpo"][cat] = {}
        db_cache["tpo"][cat]["index"], db_cache["tpo"][cat]["meta"] = load_db(
            os.path.join(tpo_root, cat)
        )

        # style DBëŠ” ìˆëŠ” ê²½ìš°ë§Œ
        style_cat_dir = os.path.join(style_root, cat)
        if os.path.exists(style_cat_dir):
            db_cache["style"][cat] = {}
            db_cache["style"][cat]["index"], db_cache["style"][cat]["meta"] = load_db(
                style_cat_dir
            )
        else:
            db_cache["style"][cat] = None  # ğŸ”¥ ì¤‘ìš”

    return db_cache

# ===============================
# 2. Input
# ===============================

def pick_persona():
    persona_input = int(input(PERSONA))
    return PERSONA_MAP[persona_input]


def get_tpo():
    return input("\nTPOë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”: ").strip()


def get_negatives():
    print("ë¹„ì„ í˜¸ ìš”ì†Œë¥¼ ì¡°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n")
    fit_input = int(input("[ë¹„ì„ í˜¸ ìš”ì†Œ 1] fit\n ë‹¤ìŒ ì¤‘ ë¹„ì„ í˜¸í•˜ëŠ” ìš”ì†Œë¥¼ ë²ˆí˜¸ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.\n1. ì˜¤ë²„ì‚¬ì´ì¦ˆ  2. ìŠ¬ë¦¼  3. ì—†ìŒ\n"))
    fit_info = NEGATIVE_MAP["fit"][fit_input]

    pattern_input = int(input("[ë¹„ì„ í˜¸ ìš”ì†Œ 2] pattern\në‹¤ìŒ ì¤‘ ë¹„ì„ í˜¸í•˜ëŠ” ìš”ì†Œë¥¼ ë²ˆí˜¸ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.\n1. ë¡œê³   2. ìŠ¤íŠ¸ë¼ì´í”„  3. ì²´í¬  4. ì—†ìŒ\n"))
    pattern_info = NEGATIVE_MAP["pattern"][pattern_input]

    price_input = int(input("[ë¹„ì„ í˜¸ ìš”ì†Œ 3] price\n ë‹¤ìŒ ì¤‘ í‰ì†Œ ì˜· í•œ ë²Œì— ì†Œë¹„ ê°€ëŠ¥í•œ ìµœëŒ€ ê¸ˆì•¡ì„ ê³¨ë¼ì£¼ì„¸ìš”.\n1. 10ë§Œì›  2. 20ë§Œì›  3. 30ë§Œì›  4. 50ë§Œì›  5. ê·¸ ì´ìƒ ì†Œë¹„ ê°€ëŠ¥\n"))
    price_info = NEGATIVE_MAP["price"][price_input] # thresholdë¡œ ì‚¬ìš©ë¨

    return {
            "fit": [fit_info] if fit_info else [],
            "pattern": [pattern_info] if pattern_info else [],
            "price_raw": price_info
            }


# =============================================================================================
# 3. OpenAI API: parse_tpo, judge_conflict, rerank_with_llm, generate_reason, update_query
# =============================================================================================

def get_client():
    # í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY ì‚¬ìš©
    return OpenAI(api_key=os.environ["OPENAI_API_KEY"])

def parse_tpo(tpo_text: str):
    print("ğŸ‘‰ Parsing the tpo...")
    client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])
    res = client.chat.completions.create(
        model="gpt-4o",
        temperature=0,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": TPO_PARSE_PROMPT},
            {
        "role": "user",
        "content": "1ì›”ì— íšŒì‚¬ ë©´ì ‘ì„ ë³´ëŸ¬ ê°€ì„œ ë‹¨ì •í•˜ê³  ê¹”ë”í•œ ë©´ì ‘ë£©ì„ ì¶”ì²œë°›ê³  ì‹¶ì–´."
    },
    {
        "role": "assistant",
        "content": json.dumps(
            {
                "parsed_keywords": ["1ì›”ì— íšŒì‚¬ ë©´ì ‘", "ë‹¨ì •í•˜ê³  ê¹”ë”í•œ ë©´ì ‘ë£©"]
            },
            ensure_ascii=False
        )
    },

    # shot 2
    {
        "role": "user",
        "content": "ë‚¨ìì¹œêµ¬ì™€ 2ë°• 3ì¼ ë¶€ì‚°ìœ¼ë¡œ ì—¬í–‰ ê°€ëŠ”ë° í¸í•˜ë©´ì„œë„ ì˜ˆìœ ìŠ¤íƒ€ì¼ ì¶”ì²œë°›ê³  ì‹¶ì–´."
    },
    {
        "role": "assistant",
        "content": json.dumps(
            {
                "parsed_keywords": ["ë‚¨ìì¹œêµ¬ì™€ ì—¬í–‰", "í¸ì•ˆí•œ ìŠ¤íƒ€ì¼", "ì˜ˆìœ ì—¬ì¹œë£©"]
            },
            ensure_ascii=False
        )
    },

            {"role": "user", "content": tpo_text},
        ]
    )
    parsed = json.loads(res.choices[0].message.content)
    return parsed.get("parsed_keywords", [])

def judge_conflict(persona: str, parsed_tpo: list) -> bool:
    print("ğŸ‘‰ Judging tpo and style conflict...")
    client = get_client()

    payload = {
        "persona": persona,
        "persona_mood": PERSONA_MOOD[persona],
        "tpo": parsed_tpo
    }

    res = client.chat.completions.create(
        model="gpt-4o",
        temperature=0,
        response_format={"type":"json_object"},
        messages=[
            {"role":"system", "content": MATCH_CLASSIFY_PROMPT},
            {"role":"user", "content": json.dumps(payload, ensure_ascii=False)}
        ]
    )

    obj = json.loads(res.choices[0].message.content)
    return bool(obj["conflict"])

def rerank_with_llm(
    persona,
    parsed_tpo,
    conflict,
    fused_candidates,
    selected_items,
    topk=3
):
    print("ğŸ‘‰ Items are reranking with llm...")
    client = get_client()

    def summarize(item):
        return {
            "product_id": str(item.get("product_id")),
            "sub_category": item.get("sub_cat_name"),
            "style": item.get("style"),
            "fit": item.get("fit"),
            "pattern": item.get("pattern"),
            "texture": item.get("texture"),
            "color": item.get("color"),
            "tpo": item.get("tpo"),
            "description": item.get("description"),
            "img_url": item.get("img_url")
        }

    payload = {
        "persona": persona,
        "persona_mood": PERSONA_MOOD[persona],
        "parsed_tpo": parsed_tpo,
        "conflict": conflict,
        "selected_items": selected_items,          # ğŸ”¥ ì¡°í™” anchor
        "candidates": [summarize(x) for x in fused_candidates]
    }

    res = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.2,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": HARMONY_RERANK_PROMPT},
            {"role": "user", "content": json.dumps(payload, ensure_ascii=False)}
        ]
    )

    obj = json.loads(res.choices[0].message.content)
    return obj["top_items"][:topk]

def build_reason_query(persona, parsed_tpo):
    tpo_text = ", ".join(parsed_tpo)
    persona_text = ", ".join(PERSONA_MOOD[persona])
    return f"ì¶”ì²œìƒí™©(TPO): {tpo_text}\ní˜ë¥´ì†Œë‚˜ ìŠ¤íƒ€ì¼: {persona_text}"

def generate_reason(reason_query: str, selected_context_text: str, item_desc: str):
    print("ğŸ‘‰ Reason for recommendation is generating...")
    client = get_client()

    reason_input = f"""
[TPO & PERSONA]
{reason_query}

[ì´ë¯¸ ì„ íƒëœ ì•„ì´í…œ]
{selected_context_text if selected_context_text else "ì—†ìŒ"}

[í˜„ì¬ ì¶”ì²œ ì•„ì´í…œ]
{item_desc}
""".strip()

    response = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.0,
        messages=[
            {"role":"system", "content": REASON_GENERATE_PROMPT},
            # few-shot
            {"role":"user", "content": """
[TPO & PERSONA]
ì¶”ì²œìƒí™©(TPO): íšŒì‚¬ ë©´ì ‘, ë‹¨ì •í•˜ê³  ê¹”ë”í•œ ë©´ì ‘ë£©
í˜ë¥´ì†Œë‚˜ ìŠ¤íƒ€ì¼: í¬ë©€, ë‹¨ì •, í”„ë ˆí”¼

[ì´ë¯¸ ì„ íƒëœ ì•„ì´í…œ]
- ìƒì˜(ì…”ì¸ ): ë¶€ë“œëŸ½ê³  íƒ„íƒ„í•œ ì½”íŠ¼ ì†Œì¬ì˜ ì¿¨í•œ ì…”ì¸ 

[í˜„ì¬ ì¶”ì²œ ì•„ì´í…œ]
ë°”ì§€(ìŠ¬ë™ìŠ¤): ë‹¤í¬ ë„¤ì´ë¹„ ìƒ‰ìƒì˜ ë‹¨ì •í•˜ê³  ê¹”ë”í•œ ìŠ¬ë™ìŠ¤
""".strip()},
            {"role":"assistant", "content": "ë‹¤í¬ ë„¤ì´ë¹„ ìŠ¬ë™ìŠ¤ëŠ” ì²«ì¸ìƒì„ ì°¨ë¶„í•˜ê²Œ ì¡ì•„ì£¼ë©´ì„œë„ ì‹¤ë£¨ì—£ì´ ê¹”ë”í•´ ë©´ì ‘ ìë¦¬ì—ì„œ ì‹ ë¢°ê°ì„ ì¤ë‹ˆë‹¤. ì•ì„œ ê³ ë¥¸ ì½”íŠ¼ ì…”ì¸ ì™€ í†¤ì˜¨í†¤ìœ¼ë¡œ ì´ì–´ì ¸ ì „ì²´ ë£©ì´ ì •ëˆë¼ ë³´ì´ê³ , ì˜¤ë˜ ì•‰ì•„ ìˆì–´ë„ ííŠ¸ëŸ¬ì§ì´ ëœí•´ìš”."},
            {"role":"user", "content": reason_input},
        ]
    )
    return response.choices[0].message.content.strip()

def refine_tpo_text(tpo_raw: str):
    print("ğŸ‘‰ Refining TPO text...")
    client = get_client()

    # TPO ì¶”ì¶œì„ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë³„ë„ ì •ì˜ í•„ìš”)
    TPO_REFINE_PROMPT = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì—ì„œ í•µì‹¬ TPO(ìƒí™©, ì¥ì†Œ, ëª©ì )ë§Œ ì¶”ì¶œí•˜ì—¬ ì§§ê³  ê°„ê²°í•œ í‚¤ì›Œë“œë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
- ë¶ˆí•„ìš”í•œ ì„œìˆ ì–´(~í•´ì¤˜, ~í•˜ê³  ì‹¶ì–´ ë“±)ë¥¼ ì œê±°í•˜ì„¸ìš”.
- '~ë£©', '~ìƒí™©' ë“±ì˜ ëª…ì‚¬í˜• í‚¤ì›Œë“œë¡œ ìš”ì•½í•˜ì„¸ìš”.
- ì¶œë ¥ì€ ë°˜ë“œì‹œ ì •ì œëœ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
""".strip()

    response = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.0,  # ì¼ê´€ì„±ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
        messages=[
            {"role": "system", "content": TPO_REFINE_PROMPT},
            # Few-shot ì˜ˆì‹œë¡œ ê°€ì´ë“œ ì œê³µ
            {"role": "user", "content": "ë‚¨ìì¹œêµ¬ì™€ ë°ì´íŠ¸í•  ë•Œ ì…ì„ ì˜· ì¶”ì²œí•´ì¤˜"},
            {"role": "assistant", "content": "ë‚¨ìì¹œêµ¬ì™€ ë°ì´íŠ¸ë£©"},
            {"role": "user", "content": "ê²°í˜¼ì‹ í•˜ê°ìœ¼ë¡œ ê°€ëŠ”ë° ê¹”ë”í•˜ê²Œ ì…ê³  ì‹¶ì–´"},
            {"role": "assistant", "content": "ê²°í˜¼ì‹ í•˜ê°ë£©"},
            {"role": "user", "content": "íšŒì‚¬ ë©´ì ‘ ë³´ëŸ¬ ê°ˆ ë•Œ ì‹ ë¢°ê°ì„ ì£¼ëŠ” ë³µì¥"},
            {"role": "assistant", "content": "íšŒì‚¬ ë©´ì ‘ë£©"},
            # ì‹¤ì œ ì…ë ¥ê°’
            {"role": "user", "content": tpo_raw},
        ]
    )
    return response.choices[0].message.content.strip()

def update_query_with_feedback(prev_query: str, feedback_text: str):
    print("ğŸ‘‰ Query is being updated with feedback...")
    client = get_client()
    payload = {
        "PERSONA_SUMMARY": prev_query,   # âœ… í”„ë¡¬í”„íŠ¸ ë¬¸êµ¬ì— ë§ì¶¤
        "user_feedback": feedback_text   # âœ… í”„ë¡¬í”„íŠ¸ ë¬¸êµ¬ì— ë§ì¶¤
    }
    res = client.chat.completions.create(
        model="gpt-4o",
        temperature=0,
        response_format={"type":"json_object"},
        messages=[
            {"role":"system", "content": UPDATE_QUERY_PROMPT},
            {"role":"user", "content": json.dumps(payload, ensure_ascii=False)}
        ]
    )
    return json.loads(res.choices[0].message.content)["updated_query"]

# -------------------------------
# 4. Retrieve
# -------------------------------

def retrieve_from_faiss(persona, model, index, metas, query_text, negatives, user_gender, hard_constraints=None, topk=5):
    # dense search (faiss)
    qvec = embed_text(query_text, model).reshape(1, -1)
    faiss.normalize_L2(qvec)

    search_k = min(len(metas), topk * 30) # 10ê°œ
    D, I = index.search(qvec, search_k)
    print(f"DEBUG: {len(I[0])} items found in FAISS") # 1. ê²€ìƒ‰ëœ ê°œìˆ˜ í™•ì¸

    results = []
    for rank_i, idx in enumerate(I[0]):
        if idx < 0:
            continue
        meta = metas[idx].copy()

        # gender filter
        if user_gender == "ë‚¨ì" and meta.get("gender") == "ì—¬":
            continue
        if user_gender == "ì—¬ì" and meta.get("gender") == "ë‚¨":
            continue

        # persona filter
        if persona == "pme" or persona == "promie":
            if meta.get("style") == "ìŠ¤íŠ¸ë¦¿":
                continue
            
        # ---------- sub category ----------
        if hard_constraints["forced_sub_categories"]:
            sub_cat = meta.get("sub_cat_name")
            if sub_cat != hard_constraints["forced_sub_categories"][-1]: # ì—¬ëŸ¬ ê°œê°€ ìˆì„ ìˆ˜ ìˆëŠ”ë° ë§ˆì§€ë§‰ ê±¸ë¡œ 
                continue
        
        # ---------- color ----------
        if hard_constraints["preferred_colors"]:
            color = meta.get("color")
            main_color = color.split(", ")[0] # ì£¼ìš” ìƒ‰ìƒ
            print(f"main_color: {main_color}")
            
            if not any(pref in main_color for pref in hard_constraints['preferred_colors']): # preferred colorsì˜ ìš”ì†Œê°€ colorì— í¬í•¨ë¼ ìˆì§€ ì•Šìœ¼ë©´ continue
                continue

        # ---------- fit ----------
        if hard_constraints["preferred_fits"]:
            fit = meta.get("fit")
            if fit != hard_constraints["preferred_fits"][-1]: # ì—¬ëŸ¬ ê°œê°€ ìˆì„ ìˆ˜ ìˆëŠ”ë° ë§ˆì§€ë§‰ ê±¸ë¡œ 
                continue

        # ---------- pattern ----------
        if hard_constraints["preferred_patterns"]:
            pattern = meta.get("pattern")
            if pattern != hard_constraints["preferred_patterns"][-1]: # ì—¬ëŸ¬ ê°œê°€ ìˆì„ ìˆ˜ ìˆëŠ”ë° ë§ˆì§€ë§‰ ê±¸ë¡œ 
                continue

        # ---------- texture ----------
        if hard_constraints["preferred_textures"]:
            texture = meta.get("texture")
            if texture != hard_constraints["preferred_textures"][-1]: # ì—¬ëŸ¬ ê°œê°€ ìˆì„ ìˆ˜ ìˆëŠ”ë° ë§ˆì§€ë§‰ ê±¸ë¡œ 
                continue

        # negative filter
        if meta.get("fit") in negatives["fit"]:
            continue
        if meta.get("pattern") in negatives["pattern"]:
            continue
        if meta.get("price_raw", 0) > negatives["price_raw"]:
            continue

        meta["score"] = float(D[0][rank_i])
        results.append(meta)
        if len(results) >= topk:
            break
        
    print(f"DEBUG: {len(results)} items are left") # ìµœì¢… ê²€ìƒ‰ëœ ê°œìˆ˜ í™•ì¸
    return results

def retrieve_candidates_by_category(persona, category, style_query, tpo_query, db_cache, model, negatives, user_gender, hard_constraints=None, topk=5):
    print("ğŸ‘‰ Retrieve items...")

    style_items = []
    if db_cache["style"][category] is not None:
        style_items = retrieve_from_faiss(
            persona,
            model,
            db_cache["style"][category]["index"],
            db_cache["style"][category]["meta"],
            style_query,
            negatives,
            user_gender,
            hard_constraints,
            topk
        )

    tpo_items = retrieve_from_faiss(
        persona,
        model,
        db_cache["tpo"][category]["index"],
        db_cache["tpo"][category]["meta"],
        tpo_query,
        negatives,
        user_gender,
        hard_constraints,
        topk
    )

    return style_items, tpo_items

def print_candidates(title, items, limit=5):
    print(f"\n--- {title} (n={len(items)}) ---")
    for i, x in enumerate(items[:limit], 1):
        print(
            f"[{i}] product_id={x.get('product_id')} | "
            f"gender={x.get('gender')} | "
            f"price={x.get('price')} | "
            f"tpo={x.get('tpo')} | "
            f"style={x.get('style')} | "
            f"fit={x.get('fit')} | "
            f"pattern={x.get('pattern')} | "
            f"score={x.get('score', 0):.4f}"
        )

def print_results(i, item, reason):
    print(f"\n[{i}] product_id={item.get('product_id')}")
    print(f"sub_cat={item.get('sub_cat_name')}")
    print(f"color={item.get('color')}")
    print(f"image={item.get('img_url')}")
    print(f"price={item.get('price')}")
    print(f"fit={item.get('fit')}")
    print(f"pattern={item.get('pattern')}")
    print(f"description={item.get('description')}")
    print(f"ğŸ‘‰ ì´ìœ : {reason}")

def fuse_candidates(style_items, tpo_items, conflict, topk=5):
    merged = {}

    # 1) score ìˆ˜ì§‘ (item ë‹¨ìœ„ë¡œ)
    for item in style_items:
        pid = str(item["product_id"])
        merged.setdefault(pid, {"item": item, "style_sim": 0.0, "tpo_sim": 0.0})
        merged[pid]["style_sim"] = item["score"] # normalize + IndexFlatPì´ë¯€ë¡œ DëŠ” ê±°ë¦¬ê°€ ì•„ë‹ˆë¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„

    for item in tpo_items:
        pid = str(item["product_id"])
        merged.setdefault(pid, {"item": item, "style_sim": 0.0, "tpo_sim": 0.0})
        merged[pid]["tpo_sim"] = item["score"]

    candidates = list(merged.values())
    if not candidates:
        return []

    # 3) normalize í•¨ìˆ˜
    def normalize(vals):
        mx, mn = max(vals), min(vals)
        if mx - mn < 1e-6:
            return [0.5 for _ in vals]  # ì „ë¶€ ë¹„ìŠ·í•˜ë©´ ì¤‘ë¦½ê°’
        return [(v - mn) / (mx - mn) for v in vals]

    style_vals = [v["style_sim"] for v in merged.values()]
    tpo_vals   = [v["tpo_sim"]   for v in merged.values()]

    style_norm = normalize(style_vals)
    tpo_norm   = normalize(tpo_vals)

    # 4) ê°€ì¤‘ì¹˜ (conflict-aware)
    alpha, beta = (0.0, 1.0) if conflict else (0.5, 0.5)

    # 5) fused score ê³„ì‚°
    fused = []
    for (pid, v), s, t in zip(merged.items(), style_norm, tpo_norm):
        fused_score = alpha * s + beta * t
        fused.append((fused_score, v["item"]))

    fused.sort(key=lambda x: x[0], reverse=True)

    # 6) TOP-K itemë§Œ ë°˜í™˜
    return [item for _, item in fused[:topk]]


def print_fused_candidates(items, title="FUSED_CANDIDATES"):
    print(f"\n=== {title} (n={len(items)}) ===")
    for i, x in enumerate(items, 1):
        print(
            f"[{i}] product_id={x.get('product_id')} | "
            f"sub_category={x.get('sub_cat_name')} | "
            f"img={x.get('img_url')} |"
            f"style={x.get('style')} | "
            f"tpo={x.get('tpo')} | "
            f"fit={x.get('fit')} | "
            f"pattern={x.get('pattern')} | "
            f"price={x.get('price')} | "
            f"score={x.get('score', 'N/A')}"
        )

def lookup_item_by_id(product_id, candidates):
    pid = str(product_id)
    for item in candidates:
        if str(item.get("product_id")) == pid:
            return item
    print(f"âš ï¸ lookup_item_by_id: product_id={product_id} not found")
    return None


# --------------------------------------------------------------
# 5. build context: add selected item, context, summary
# --------------------------------------------------------------
def add_selected_item(category, selected_items: list, chosen_item: dict):
    """
    selected_items: ìœ ì €ê°€ 'í™•ì •'í•œ ì•„ì´í…œë“¤ë§Œ ì €ì¥
    ì¡°í™” ê¸°ë°˜ rerankingì˜ ê¸°ì¤€(anchor)
    """
    selected_items[category] = {
        "product_id": str(chosen_item.get("product_id")),
        "product_name": chosen_item.get("product_name"),
        "category": chosen_item.get("main_cat_name"),
        "sub_category": chosen_item.get("sub_cat_name"),
        "brand": chosen_item.get("brand"),
        "price": chosen_item.get("price"),
        "item_url": chosen_item.get("item_url"),
        "img_url": chosen_item.get("img_url"),
        "style": chosen_item.get("style_name"),
        "fit": chosen_item.get("fit"),
        "texture": chosen_item.get("texture"),
        "pattern": chosen_item.get("pattern"),
        "color": chosen_item.get("color"),      # ìˆìœ¼ë©´
        "tpo": chosen_item.get("tpo"),
        "description": chosen_item.get("description")
    }

def append_selected_context(selected_context_text: str, chosen_item: dict) -> str:
    # ì‚¬ëŒì´ ì½ì„ ì»¨í…ìŠ¤íŠ¸(ì´ìœ  ìƒì„±/ë¦¬ë­í¬ì—ì„œ ì“°ê¸°)
    line = f"- {chosen_item.get('main_cat_name')}({chosen_item.get('sub_cat_name')}): {chosen_item.get('description')}"
    return (selected_context_text + "\n" + line).strip()


# -----------------------
# 6. update feedback 
# -----------------------

def init_hard_constraints():
    return {
        "forced_sub_categories": [],

        "preferred_colors": [],

        "preferred_fits": [],

        "preferred_patterns": [],

        "preferred_textures": [],
    }


def apply_feedback_to_constraints(feedback_obj, hard_constraints):
    intent = feedback_obj["intent"]

    if intent == "sub_cat_name":
        hard_constraints["forced_sub_categories"].extend(
            feedback_obj.get("include", [])
        )

    elif intent == "color":
        hard_constraints["preferred_colors"].extend(
            feedback_obj.get("include", [])
        )
    elif intent == "fit":
        hard_constraints["preferred_fits"].extend(
            feedback_obj.get("include", [])
        )

    elif intent == "pattern":
        hard_constraints["preferred_patterns"].extend(
            feedback_obj.get("include", [])
        )

    elif intent == "texture":
        hard_constraints["preferred_textures"].extend(
            feedback_obj.get("include", [])
        )

